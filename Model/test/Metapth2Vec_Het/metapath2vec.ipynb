{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from node2vec import Node2Vec\n",
    "from igraph import Graph\n",
    "import igraph as ig\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score, confusion_matrix, log_loss, matthews_corrcoef, precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import precision_recall_fscore_support as prf_support\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from torch_geometric.nn import MetaPath2Vec\n",
    "from typing import Dict, Tuple\n",
    "import torch\n",
    "import tqdm\n",
    "\n",
    "graphss = r'C:\\Users\\George\\Desktop\\ISEF-2023\\Network construction\\Het_graph_final.graphml'\n",
    "HetG = ig.Graph.Load(graphss, format='graphml')\n",
    "graph = HetG\n",
    "\n",
    "\n",
    "def create_edge_index_dict(graph: ig.Graph):\n",
    "    edge_index_dict = {}\n",
    "    unique_to_original = {}\n",
    "    original_to_unique = {}\n",
    "\n",
    "    # Variables to keep track of unique IDs for each node type\n",
    "    current_ids = {}\n",
    "\n",
    "    for vertex in graph.vs:\n",
    "        node_type = vertex[\"type\"]\n",
    "        original_id = vertex.index\n",
    "\n",
    "        # Assign unique IDs for each node type\n",
    "        if node_type not in current_ids:\n",
    "            current_ids[node_type] = 0\n",
    "        unique_id = current_ids[node_type]\n",
    "        current_ids[node_type] += 1\n",
    "\n",
    "        # Update mappings\n",
    "        unique_to_original[(node_type, unique_id)] = original_id\n",
    "        original_to_unique[original_id] = (node_type, unique_id)\n",
    "\n",
    "    for edge in graph.es:\n",
    "        src_node_type = graph.vs[edge.source][\"type\"]\n",
    "        rel_type = edge[\"type\"]\n",
    "        dst_node_type = graph.vs[edge.target][\"type\"]\n",
    "\n",
    "        key = (src_node_type, rel_type, dst_node_type)\n",
    "\n",
    "        if key not in edge_index_dict:\n",
    "            edge_index_dict[key] = []\n",
    "\n",
    "        # Use unique IDs in edge indices\n",
    "        unique_src_id = original_to_unique[edge.source][1]\n",
    "        unique_dst_id = original_to_unique[edge.target][1]\n",
    "        edge_index_dict[key].append((unique_src_id, unique_dst_id))\n",
    "\n",
    "    # Convert the lists of edge indices to torch.Tensor\n",
    "    for key in edge_index_dict:\n",
    "        edge_index_dict[key] = torch.tensor(edge_index_dict[key], dtype=torch.long).t()\n",
    "\n",
    "    return edge_index_dict, unique_to_original, original_to_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('Protein', 'Protein-Protein-Physical', 'Protein'): tensor([[2582, 2582, 2582,  ...,  723,  723,  723],\n",
      "        [7168, 5221, 1923,  ...,  591, 3126, 2752]]), ('Protein', 'Protein-Protein-STP', 'Protein'): tensor([[2555, 2555, 2555,  ..., 3493, 3493, 3493],\n",
      "        [4190, 6645, 5829,  ..., 6923, 5475, 2182]]), ('Compound', 'Metabolite-Reaction', 'Reaction'): tensor([[  4, 171, 334,  ..., 446, 101, 358],\n",
      "        [  0,   0,   1,  ..., 444, 444, 444]]), ('Protein', 'Enzyme-Reaction', 'Reaction'): tensor([[ 389, 3826, 6099,  ..., 2706,  773,  773],\n",
      "        [   0,    1,    1,  ...,  443,  443,  444]]), ('Drug', 'Drug-Drug', 'Drug'): tensor([[3645, 3645, 3645,  ...,  583,   64, 3667],\n",
      "        [ 972, 1256, 2674,  ..., 4442,  824, 2533]]), ('Drug', 'Drug-Target', 'Protein'): tensor([[3128, 3128, 3128,  ..., 1427, 3388, 1871],\n",
      "        [5981, 2925, 6006,  ..., 3904, 1662, 7042]])}\n"
     ]
    }
   ],
   "source": [
    "edge_index_dict, unique_to_original, original_to_unique = create_edge_index_dict(HetG)\n",
    "print(edge_index_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Caught IndexError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\Users\\George\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"C:\\Users\\George\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n  File \"C:\\Users\\George\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch_geometric\\nn\\models\\metapath2vec.py\", line 193, in _sample\n    return self._pos_sample(batch), self._neg_sample(batch)\n  File \"C:\\Users\\George\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch_geometric\\nn\\models\\metapath2vec.py\", line 151, in _pos_sample\n    batch = sample(\n  File \"C:\\Users\\George\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch_geometric\\nn\\models\\metapath2vec.py\", line 245, in sample\n    rand *= rowcount[subset].to(rand.dtype).view(-1, 1)\nIndexError: index 7392 is out of bounds for dimension 0 with size 7392\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [13], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m loader \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mloader(batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m)\n\u001b[0;32m     19\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSparseAdam(\u001b[38;5;28mlist\u001b[39m(model\u001b[38;5;241m.\u001b[39mparameters()), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pos_rw, neg_rw \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(pos_rw\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1345\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1343\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1344\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[1;32m-> 1345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1371\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1369\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[0;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[1;32m-> 1371\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_utils.py:694\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    691\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[0;32m    692\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[0;32m    693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m--> 694\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[1;31mIndexError\u001b[0m: Caught IndexError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\Users\\George\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"C:\\Users\\George\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n  File \"C:\\Users\\George\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch_geometric\\nn\\models\\metapath2vec.py\", line 193, in _sample\n    return self._pos_sample(batch), self._neg_sample(batch)\n  File \"C:\\Users\\George\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch_geometric\\nn\\models\\metapath2vec.py\", line 151, in _pos_sample\n    batch = sample(\n  File \"C:\\Users\\George\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch_geometric\\nn\\models\\metapath2vec.py\", line 245, in sample\n    rand *= rowcount[subset].to(rand.dtype).view(-1, 1)\nIndexError: index 7392 is out of bounds for dimension 0 with size 7392\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "\n",
    "metapath = [\n",
    "    ('Protein', 'Protein-Protein-Physical', 'Protein'),\n",
    "    ('Protein', 'Protein-Protein-STP', 'Protein')\n",
    "]\n",
    "\n",
    "model = MetaPath2Vec(edge_index_dict,\n",
    "                     embedding_dim=128,\n",
    "                     metapath=metapath,\n",
    "                     walk_length=5,\n",
    "                     context_size=3,\n",
    "                     walks_per_node=3,\n",
    "                     num_negative_samples=1,\n",
    "                     sparse=True\n",
    "                    ).to(device)\n",
    "\n",
    "loader = model.loader(batch_size=1, shuffle=True, num_workers=6)\n",
    "optimizer = torch.optim.SparseAdam(list(model.parameters()), lr=0.01)\n",
    "\n",
    "for pos_rw, neg_rw in loader:\n",
    "    print(pos_rw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train(epoch, log_steps=100, eval_steps=2000):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    for i, (pos_rw, neg_rw) in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss(pos_rw.to(device), neg_rw.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        if (i + 1) % log_steps == 0:\n",
    "            print((f'Epoch: {epoch}, Step: {i + 1:05d}/{len(loader)}, '\n",
    "                   f'Loss: {total_loss / log_steps:.4f}'))\n",
    "            total_loss = 0\n",
    "\n",
    "        if (i + 1) % eval_steps == 0:\n",
    "            acc = test()\n",
    "            print((f'Epoch: {epoch}, Step: {i + 1:05d}/{len(loader)}, '\n",
    "                   f'Acc: {acc:.4f}'))\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(train_ratio=0.1):\n",
    "    model.eval()\n",
    "\n",
    "    z = model('author', batch=data['author'].y_index.to(device))\n",
    "    y = data['author'].y\n",
    "\n",
    "    perm = torch.randperm(z.size(0))\n",
    "    train_perm = perm[:int(z.size(0) * train_ratio)]\n",
    "    test_perm = perm[int(z.size(0) * train_ratio):]\n",
    "\n",
    "    return model.test(z[train_perm], y[train_perm], z[test_perm], y[test_perm],\n",
    "                      max_iter=150)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Caught IndexError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\Users\\George\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"C:\\Users\\George\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n  File \"C:\\Users\\George\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch_geometric\\nn\\models\\metapath2vec.py\", line 193, in _sample\n    return self._pos_sample(batch), self._neg_sample(batch)\n  File \"C:\\Users\\George\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch_geometric\\nn\\models\\metapath2vec.py\", line 151, in _pos_sample\n    batch = sample(\n  File \"C:\\Users\\George\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch_geometric\\nn\\models\\metapath2vec.py\", line 245, in sample\n    rand *= rowcount[subset].to(rand.dtype).view(-1, 1)\nIndexError: index 12719 is out of bounds for dimension 0 with size 12719\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     train(epoch)\n\u001b[0;32m      3\u001b[0m     acc \u001b[38;5;241m=\u001b[39m test()\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn [16], line 15\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(epoch, log_steps, eval_steps)\u001b[0m\n\u001b[0;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     14\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (pos_rw, neg_rw) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loader):\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m12718\u001b[39m:\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1345\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1343\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1344\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[1;32m-> 1345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1371\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1369\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[0;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[1;32m-> 1371\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_utils.py:694\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    691\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[0;32m    692\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[0;32m    693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m--> 694\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[1;31mIndexError\u001b[0m: Caught IndexError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\Users\\George\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"C:\\Users\\George\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n  File \"C:\\Users\\George\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch_geometric\\nn\\models\\metapath2vec.py\", line 193, in _sample\n    return self._pos_sample(batch), self._neg_sample(batch)\n  File \"C:\\Users\\George\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch_geometric\\nn\\models\\metapath2vec.py\", line 151, in _pos_sample\n    batch = sample(\n  File \"C:\\Users\\George\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch_geometric\\nn\\models\\metapath2vec.py\", line 245, in sample\n    rand *= rowcount[subset].to(rand.dtype).view(-1, 1)\nIndexError: index 12719 is out of bounds for dimension 0 with size 12719\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(1, 6):\n",
    "    train(epoch)\n",
    "    acc = test()\n",
    "    print(f'Epoch: {epoch}, Accuracy: {acc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
