
import requests
import json
import time
import subprocess

# Read the protein names from the text file
with open(r'C:\Users\Srisharan\OneDrive\Desktop\ISEF\ISEF-2023\Outcome_data\All_unknown_predicted_proteins.csv', 'r') as file:
    next(file)  # Skip the header line
    protein_names = [line.split(',')[0].strip() for line in file][:5]  # Limit to the first 5 names


# Loop through each of the first 5 protein names
for uniprot_name in protein_names:

    # Define the JSON payload
    payload = {
        "dogsite": {
            "pdbCode": f'{uniprot_name}',
            "analysisDetail": "1",
            "bindingSitePredictionGranularity": "1",
            "ligand": "",
            "chain": ""
        }
    }

    # Define headers
    headers = {
        "Accept": "application/json",
        "Content-Type": "application/json"
    }

    # Define the URL
    url = "https://proteins.plus/api/dogsite_rest"

    # Send POST request
    response = requests.post(url, json=payload, headers=headers)

    status_code = None

    # Keep looping until status code is 200
    while status_code != 200:
        # Send POST request
        response = requests.post(url, json=payload, headers=headers)
        # Get status code from the response
        status_code = response.status_code
        # Check if status code is not 200
        if status_code != 200:
            print("Waiting for status code 200. Current status code:", status_code)
            # Wait for 5 seconds before checking again
            time.sleep(5)

    # Once the status code is 200, parse and print the response
    response_json = response.json()
    
    new_url = response_json["location"]

    job_id = new_url.split("/")[-1]

    # Call cURL with the new URL
    subprocess.run(["curl", new_url])

    result_url = new_url.decode("utf-8")

    print(result_url['result_table'])



